{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of this notebook\n",
    "\n",
    "* introduction to time series classification, regression, clustering\n",
    "* `sktime` data format fo \"time series panels\" = collections of time series\n",
    "* basic vignettes for TSC, TSR, TScl\n",
    "* advanced vignettes - pipelines, ensembles, tuning\n",
    "* appendix: data loading\n",
    "* appendix: implementing third party estimators for TSC, TSR, TScl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Learning tasks - Classification, Regression, Clustering & more\n",
    "\n",
    "deal with *collections of time series* = \"panel data\"\n",
    "\n",
    "Classification = try to assign one *category* per time series, after training on time series/category examples\n",
    "\n",
    "Example: osuleaf - circumference point distance of leaves. Predict type of tree\n",
    "\n",
    "Regression = try to assign one *category* per time series, after training on time series/category examples\n",
    "\n",
    "Example: temperature/pressure/time profile of chemical reactor. Predict total purity (fraction of 1)\n",
    "\n",
    "Clustering = put different time series in a small number of similarity buckets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Panel data - `sktime` data formats\n",
    "\n",
    "Preferred format 1: `pd.DataFrame` with 2-level `MultiIndex`, (instance, time), cols= variables\n",
    "\n",
    "Preferred format 2: 3D `np.ndarray` with index (instance, variable, time)\n",
    "\n",
    "* `sktime` supports and recognizes multiple data formats for convenience and internal use, e.g., `dask`, `xarray`\n",
    "* abstract data type = \"scitype\"; in-memory specification = \"mtype\"\n",
    "* More information in tutorial on [in-memory data representations and data loading](https://www.sktime.net/en/latest/examples/AA_datatypes_and_datasets.html#In-memory-data-representations-and-data-loading)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 preferred format 1 - `pd-multiindex` specification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd-multiindex` = `pd.DataFrame` with 2-level `MultiIndex`, (instance, time), cols= variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_osuleaf\n",
    "\n",
    "# load an example time series panel in pd-multiindex mtype\n",
    "X, _ = load_osuleaf(return_type=\"pd-multiindex\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The osuleaf dataset has:\n",
    "\n",
    "* 412 individual time series instances\n",
    "* one single variable per time series instances, `dim_0`\n",
    "* individual time series are observed at 100 time points (the same number for all instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_basic_motions\n",
    "\n",
    "# load an example time series panel in pd-multiindex mtype\n",
    "X, _ = load_basic_motions(return_type=\"pd-multiindex\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic motions dataset has:\n",
    "\n",
    "* 6 individual time series instances\n",
    "* six variables per time series instance, `dim_0` to `dim_5`\n",
    "* individual time series are observed at 100 time points (the same number for all instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 preferred format 2 - `numpy3D` specification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numpy3D` = 3D `np.ndarray` with index (instance, variable, time)\n",
    "\n",
    "instance/time index is interpreted as integer\n",
    "\n",
    "IMPORTANT: unlike `pd-multiindex`, this assumes:\n",
    "\n",
    "* all individual series have the same length\n",
    "* all individual series have the same index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_osuleaf\n",
    "\n",
    "# load an example time series panel in numpy mtype\n",
    "X, _ = load_osuleaf(return_type=\"numpy3D\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The osuleaf dataset has:\n",
    "\n",
    "* 412 individual time series instances\n",
    "* one single variable per time series instances\n",
    "* individual time series are observed at 100 time points (the same number for all instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_basic_motions\n",
    "\n",
    "# load an example time series panel in numpy mtype\n",
    "X, _ = load_basic_motions(return_type=\"numpy3D\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic motions dataset has:\n",
    "\n",
    "* 6 individual time series instances\n",
    "* six variables per time series instance\n",
    "* individual time series are observed at 100 time points (the same number for all instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 loading and validity checking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for custom data sets:\n",
    "\n",
    "1. use `pandas` `read_csv` or similar utilities to obtain a `pd.DataFrame` or `np.ndarray`\n",
    "2. try to bring the result in one of the preferred specifications\n",
    "3. use the `check_is_mtype` utility to check compliance - inspect informative error messages\n",
    "4. repeate 2-3 until the data format check passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's pretend we just loaded this from csv\n",
    "from sktime.datasets import load_osuleaf\n",
    "\n",
    "X_pd, _ = load_osuleaf(return_type=\"pd-multiindex\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's now check whether it complies with the `pd-multiindex` specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datatypes import check_is_mtype\n",
    "\n",
    "valid, error_msg, metadata = check_is_mtype(X_pd, \"pd-multiindex\", return_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is it valid?\n",
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpful metadata, check if this is as per expectations\n",
    "metadata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's see what happens if it is not in the expected format.\n",
    "\n",
    "We have a `pd.DataFrame`, so if we check against `numpy3D`, it should complain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid, error_msg, metadata = check_is_mtype(X_pd, \"numpy3D\", return_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_msg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that we should first convert into `np.ndarray` as expected."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further details on data formats, see the tutorial on [in-memory data representations and data loading](https://www.sktime.net/en/latest/examples/AA_datatypes_and_datasets.html#In-memory-data-representations-and-data-loading).\n",
    "\n",
    "The \"datatypes\" tutorial also contains:\n",
    "\n",
    "* full formal specifications of the mtypes (= machine representations)\n",
    "* common examples for loading from csv and formatting\n",
    "* utilities for loading data for commonly used benchmark problems\n",
    "\n",
    "All supported in-memory representations are python inspectable in `sktime.datatypes.MTYPE_REGISTER`\n",
    "\n",
    "Note that this includes \"exotic\", rarely used ones and representations of objects that aren't time series.\n",
    "Formats for time series panels are indicated by the `Panel` mtype.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Time Series Classification, Regression, Clustering - Basic Vignettes\n",
    "\n",
    "Above tasks are very similar to \"tabular\" classification, regression, clustering, as in `sklearn`\n",
    "\n",
    "Main distinction:\n",
    "* in \"tabular\" classification etc, one (feature) instance row vector of features\n",
    "* in TSC, one (feature) instance is a full time series, possibly unequal length, distinct index set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: INSERT HELPFUL PICTURE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "More formally:\n",
    "\n",
    "* \"tabular\" classification: training pairs $(x_1, y_1), \\dots, (x_n, y_n)$, where $x_i$ are rows of a `pd.DataFrame` (same col types), and $y_i \\in \\mathcal{C}$ for a finite set $y_i \\in \\mathcal{C}$. We use these to train a classifier that predicts $y_* \\in \\mathcal{C}$ for a `pd.DataFrame` row $x_*$\n",
    "* time series classification: training pairs $(x_1, y_1), \\dots, (x_n, y_n)$, where $x_i$ are time series from a certain domain, and $y_i \\in \\mathcal{C}$ for a finite set $y_i \\in \\mathcal{C}$. We use these to train a classifier that predicts $y_* \\in \\mathcal{C}$ for time series $x_*$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "very similar for time series regression, clustering - exercise left to reader :-)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sktime` design implications:\n",
    "\n",
    "* need representation of collections of time series (panels), see Section 2.1\n",
    "    * same as in \"adjacent\" learning tasks, e.g., panel forecasting\n",
    "    * same as for transformation estimators\n",
    "* algorithms that use sequentiality, can deal with unequal length etc\n",
    "* algorithms usually based on distances or kernels between time series - need to cover that in framework\n",
    "* but we can use familiar `fit` / `predict` and `scikit-learn` / `scikit-base` interface!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Time Series Classification - deployment vignette"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic deployment vignette for TSC:\n",
    "\n",
    "1. load/setup training data, `X` in a `Panel` format, `y` as 1D `np.ndarray`\n",
    "2. load/setup new data for prediction (can be done after 2 too)\n",
    "3. specify the classifier using `sklearn`-like syntax\n",
    "4. fit classifier to training data, `fit(X, y)`\n",
    "5. predict labels on new data, `predict(X_new)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps 1, 2 - prepare osuleaf dataset (train and new)\n",
    "from sktime.datasets import load_osuleaf\n",
    "\n",
    "X_train, y_train = load_osuleaf(split=\"train\", return_type=\"numpy3D\")\n",
    "X_new, _ = load_osuleaf(split=\"test\", return_type=\"numpy3D\")\n",
    "X_new = X_new[:2]  # smaller dataset for faster notebook runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is in numpy3D format, but could also be pd-multiindex or other\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y is a 1D np.ndarray of labels - same length as number of instances in X_train\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 - specify the classifier\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "\n",
    "# example 1 - 3-NN with simple dynamic time warping distance (requires numba)\n",
    "clf = KNeighborsTimeSeriesClassifier(n_neighbors=3)\n",
    "\n",
    "# example 2:\n",
    "# 3-nearest neighbour classifier with mean (over time points) pairwise Euclidean distance\n",
    "# (requires scipy)\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.dists_kernels.compose_tab_to_panel import AggrDist\n",
    "from sktime.dists_kernels import ScipyDist\n",
    "\n",
    "mean_eucl_dist = AggrDist(ScipyDist())\n",
    "clf = KNeighborsTimeSeriesClassifier(n_neighbors=3, distance=mean_eucl_dist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we could specify any `sktime` classifier here - the rest remains the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all classifiers is scikit-learn / scikit-base compatible!\n",
    "# nested parameter interface via get_params, set_params\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4 - fit/train the classifier\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the classifier is now fitted\n",
    "clf.is_fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and we can inspect fitted parameters if we like\n",
    "clf.get_fitted_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5 - predict labels on new data\n",
    "y_pred = clf.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred is an 1D np.ndarray, similar to sklearn classification output\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all together in one cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps 1, 2 - prepare osuleaf dataset (train and new)\n",
    "from sktime.datasets import load_osuleaf\n",
    "\n",
    "X_train, y_train = load_osuleaf(split=\"train\", return_type=\"numpy3D\")\n",
    "X_new, _ = load_osuleaf(split=\"test\", return_type=\"numpy3D\")\n",
    "X_new = X_new[:2]  # smaller dataset for faster notebook runtime\n",
    "\n",
    "# step 3 - specify the classifier\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.dists_kernels.compose_tab_to_panel import AggrDist\n",
    "from sktime.dists_kernels import ScipyDist\n",
    "\n",
    "mean_eucl_dist = AggrDist(ScipyDist())\n",
    "clf = KNeighborsTimeSeriesClassifier(n_neighbors=3, distance=mean_eucl_dist)\n",
    "\n",
    "# step 4 - fit/train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# step 5 - predict labels on new data\n",
    "y_pred = clf.predict(X_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 Time Series Classification - simple evaluation vignette"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation is simila to `sklearn` classifiers - we split a dataset and evaluate performance on the test set.\n",
    "\n",
    "This includes as additional steps:\n",
    "\n",
    "* splitting the initial, historical data, e.g., using `train_test_split`\n",
    "* comparing predictions with a held out data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.datasets import load_osuleaf\n",
    "\n",
    "# data should be split inti train/test\n",
    "X_train, y_train = load_osuleaf(split=\"train\", return_type=\"numpy3D\")\n",
    "X_test, y_test = load_osuleaf(split=\"test\", return_type=\"numpy3D\")\n",
    "X_test = X_test[:2]\n",
    "y_test = y_test[:2]\n",
    "\n",
    "# step 3-5 are the same\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.dists_kernels.compose_tab_to_panel import AggrDist\n",
    "from sktime.dists_kernels import ScipyDist\n",
    "\n",
    "mean_eucl_dist = AggrDist(ScipyDist())\n",
    "clf = KNeighborsTimeSeriesClassifier(n_neighbors=3, distance=mean_eucl_dist)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# for simplest evaluation, compare ground truth to predictions\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 Time Series Regression - basic vignettes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TSR vignettes are exactly the same as TSC, except that:\n",
    "\n",
    "* `y` in `fit` input and `predict` output should be float 1D `np.ndarray`, not categorical\n",
    "* other algorithms are commonly used and/or performant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps 1, 2 - prepare osuleaf dataset (train and new)\n",
    "from sktime.datasets import load_covid_3month\n",
    "\n",
    "X_train, y_train = load_covid_3month(split=\"train\", return_type=\"numpy3D\")\n",
    "X_new, _ = load_covid_3month(split=\"test\", return_type=\"numpy3D\")\n",
    "X_new = X_new.loc[:2]  # smaller dataset for faster notebook runtime\n",
    "\n",
    "# step 3 - specify the regressor\n",
    "from sktime.regression.distance_based import KNeighborsTimeSeriesRegressor\n",
    "\n",
    "clf = KNeighborsTimeSeriesRegressor(n_neighbors=3)\n",
    "\n",
    "# step 4 - fit/train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# step 5 - predict labels on new data\n",
    "y_pred = clf.predict(X_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.6 Time Series Classification - basic vignettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Searching for estimators, estimator tags"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimators in `sktime` are tagged.\n",
    "\n",
    "Tags starting with \"capability\" indicate things the estimator can or cannot do, e.g.,\n",
    "\n",
    "* `\"capability:missing_values\"` - dealing with missing values\n",
    "* `\"capability:multivariate\"` - daling with multivariate input\n",
    "* `\"capability:unequal_length\"` - deaing with time series panels where the individual time series have unequal length and/or unequal index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all tags for an estimator scitype (e.g., classifier, regressor) can be inspected by `sktime.registry.all_tags`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.registry import all_tags\n",
    "\n",
    "all_tags(\"classifier\", as_dataframe=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valid estimator types are listed in the `all_tags` docstring, or `sktime.registry.BASE_CLASS_REGISTER`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.registry import BASE_CLASS_REGISTER\n",
    "\n",
    "# get only fist table column, the list of types\n",
    "list(zip(*BASE_CLASS_REGISTER))[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to find all estimators of a certain type, use `sktime.registry.all_estimators`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all classifiers in sktime\n",
    "from sktime.registry import all_estimators\n",
    "\n",
    "all_estimators(\"classifier\", as_dataframe=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for listing all estimators of a certain type with a certain capability,\n",
    "use the `filter_tags` argument of `all_estimators`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all classifiers in sktime\n",
    "# that can classify panels of time series containing missing data\n",
    "from sktime.registry import all_estimators\n",
    "\n",
    "all_estimators(\"classifier\", as_dataframe=True, filter_tags={\"capability:missing_values\": True})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "side note:\n",
    "\n",
    "don't worry about how short the list is - when in doubt, it is always possible to pipeline with `Imputer`\n",
    "\n",
    "as in the next section :-)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Pipelines, Feature Extraction, Tuning, Composition\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similar to `sklearn` for \"tabular\" classification, regression, etc,\n",
    "\n",
    "`sktime` has a rich set of tools for:\n",
    "\n",
    "* feature extraction via transformers\n",
    "* pipeline transformers with any estimator\n",
    "* tuning individual estimators or pipelines via grid search and similar\n",
    "* building ensembles out of individual estimators, or other composites\n",
    "\n",
    "`sktime` is also fully interoperable with `sklearn` interface if `numpy` based data mtypes are used\n",
    "\n",
    "(although this loses support for unequal length time series)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Primer on `sktime` transformers for feature extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all `sktime` transformers work natively with panel data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_osuleaf\n",
    "from sktime.transformations.series.detrend import Detrender\n",
    "\n",
    "# load some panel data\n",
    "X, _ = load_osuleaf(return_type=\"pd-multiindex\")\n",
    "\n",
    "# specify a linear detrender\n",
    "detrender = Detrender()\n",
    "\n",
    "# detrend X by removing linear trend from each instance\n",
    "X_detrended = detrender.fit_transform(X)\n",
    "X_detrended.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for panel tasks such as TSC, TSR, clustering, there are two distinctions to be aware of:\n",
    "\n",
    "* series-to-series transformers transform individual series to series, panels to panels. E.g., instance-wise detrender above\n",
    "* series-to-primitive transformers transform individual series to a set of tabular features. E>g., summary feature extractor\n",
    "\n",
    "either type of transform can be instance-wise:\n",
    "\n",
    "* instance-wise transforms use only the i-th series to transform the i-th series. E.g., instance-wise detrender\n",
    "* non-instance-wise transforms train on all series to transform the i-th series. E.g., PCA, overall mean detrender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a series-to-primitive transformer\n",
    "from sktime.transformations.series.summarize import SummaryTransformer\n",
    "\n",
    "# specify summary transformer\n",
    "summary_trafo = SummaryTransformer()\n",
    "\n",
    "# extract summary features - one per instance in the panel\n",
    "X_summaries = summary_trafo.fit_transform(X)\n",
    "X_summaries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just like classifiers, we can search for transformers of either type via the right tag:\n",
    "\n",
    "* `\"scitype:transform-input\"` and `\"scitype:transform-output\"` define input and output, e.g., \"series-to-series\" (both are scitype strings)\n",
    "* `\"scitype:instancewise\"` is boolean and tells us whether the transform is instance-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: looking for all series-to-primitive transformers that are instance-wise\n",
    "from sktime.registry import all_estimators\n",
    "\n",
    "all_estimators(\n",
    "    \"transformer\",\n",
    "    as_dataframe=True,\n",
    "    filter_tags={\n",
    "        \"scitype:transform-input\": \"Series\",\n",
    "        \"scitype:transform-output\": \"Primitives\",\n",
    "        \"scitype:instancewise\": True,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further details on transformations and feature extraction can be found in the tutorial 3, transformers.\n",
    "\n",
    "All composition steps therein (e.g., chaining, column subsetting) work together with all estimator types in `sktime`, including classifiers, regressors, clusterers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Pipelines for time series panel tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.transformations.series.exponent import ExponentTransformer\n",
    "\n",
    "pipe = ExponentTransformer() * KNeighborsTimeSeriesClassifier()\n",
    "\n",
    "# this constructs a ClassifierPipeline, which is also a classifier\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative to construct:\n",
    "from sktime.pipeline import make_pipeline\n",
    "\n",
    "pipe = make_pipeline(ExponentTransformer(), KNeighborsTimeSeriesClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_unit_test\n",
    "\n",
    "X_train, y_train = load_unit_test(split=\"TRAIN\")\n",
    "X_test, _ = load_unit_test(split=\"TEST\")\n",
    "\n",
    "# this is a forecaster with the same interface as knn-classifier\n",
    "# first applies exponent transform, then knn-classifier\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 Using transformers to deal with unequal length or missing values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pro tipp: useful transformers to pipeline are those that \"improve\" capabilities!\n",
    "\n",
    "Search for these transformer tags:\n",
    "\n",
    "* `\"capability:unequal_length:removes\"` - ensures all instances in the panel have equal length afterwards. Examples: padding, cutting, resampling.\n",
    "* `\"capability:missing_values:removes\"` - removes all missing values from the data (e.g., series, panel) passed to it. Example: mean imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all transformers that guarantee that the output is equal length and equal index\n",
    "from sktime.registry import all_estimators\n",
    "\n",
    "all_estimators(\"transformer\", as_dataframe=True, filter_tags={\"capability:unequal_length:removes\": True })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all transformers that guarantee the output has no missing values\n",
    "from sktime.registry import all_estimators\n",
    "\n",
    "all_estimators(\"transformer\", as_dataframe=True, filter_tags={\"capability:missing_values:removes\": True })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "minor note:\n",
    "\n",
    "some transformers guarantee \"no missing values\" under some conditions but not always, e.g., `TimeBinAggregate`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's check the tags in one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all classifiers in sktime\n",
    "from sktime.classification.feature_based import MatrixProfileClassifier\n",
    "\n",
    "no_missing_clf = MatrixProfileClassifier()\n",
    "\n",
    "no_missing_clf.get_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.series.impute import Imputer\n",
    "\n",
    "clf_can_do_missing = Imputer() * MatrixProfileClassifier()\n",
    "\n",
    "clf_can_do_missing.get_tags()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.4 Tuning and AutoML"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sktime` classifiers are compatible with `sklearn` model selection and composition tools using `sktime` data formats.\n",
    "\n",
    "This extends to grid tuning and cross-validation, as long as `numpy` based formats or length/instance indexed formats are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_unit_test\n",
    "\n",
    "X_train, y_train = load_unit_test(split=\"TRAIN\")\n",
    "X_test, _ = load_unit_test(split=\"TEST\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation using the `sklearn` `cross_val_score` and `KFold` functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sktime.classification.feature_based import MatrixProfileClassifier\n",
    "\n",
    "clf = MatrixProfileClassifier()\n",
    "\n",
    "cross_val_score(clf, X_train, y=y_train, cv=KFold(n_splits=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter tuning using `sklearn` `GridSearchCV`, we tune the _k_ and distance measure for a K-NN classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "\n",
    "knn = KNeighborsTimeSeriesClassifier()\n",
    "param_grid = {\"n_neighbors\": [1, 5], \"distance\": [\"euclidean\", \"dtw\"]}\n",
    "parameter_tuning_method = GridSearchCV(knn, param_grid, cv=KFold(n_splits=4))\n",
    "\n",
    "parameter_tuning_method.fit(X_train, y_train)\n",
    "y_pred = parameter_tuning_method.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability calibration with the `sklearn` `CalibratedClassifierCV`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sktime.classification.interval_based import DrCIF\n",
    "\n",
    "calibrated_clf = CalibratedClassifierCV(\n",
    "    base_estimator=DrCIF(n_estimators=10, n_intervals=5), cv=4\n",
    ")\n",
    "\n",
    "calibrated_clf.fit(X_train, y_train)\n",
    "y_pred = calibrated_clf.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.5 Advanced Composition examples - bagging, weighted ensemble"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pro tipp: bagging with a fixed single column subset can be used to turn an univariate classifier into a multivariate classifier!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Appendix - Extension guide"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sktime` is meant to be easily extensible, for direct contribution to `sktime` as well as for local/private extension with custom methods.\n",
    "\n",
    "To extend `sktime` with a new local or contributed estimator, a good workflow to follow is:\n",
    "\n",
    "0. find the right extension template for the type of estimator you want to add - e.g., classifier, regressor, clusterer, etc. The extension templates are located in the [`extension_templates](https://github.com/sktime/sktime/blob/main/extension_templates) directory\n",
    "1. read through the extension template - this is a `python` file with `todo` blocks that mark the places in which changes need to be added.\n",
    "2. optionally, if you are planning any major surgeries to the interface: look at the base class - note that \"ordinary\" extension (e.g., new algorithm) should be easily doable without this.\n",
    "3. copy the extension template to a local folder in your own repository (local/private extension), or to a suitable location in your clone of the `sktime` or affiliated repository (if contributed extension), inside `sktime.[name_of_task]`; rename the file and update the file docstring appropriately.\n",
    "4. address the \"todo\" parts. Usually, this means: changing the name of the class, setting the tag values, specifying hyper-parameters, filling in `__init__`, `_fit`, `_predict` and/or other methods (for details see the extension template). You can add private methods as long as they do not override the default public interface. For more details, see the extension template.\n",
    "5. to test your estimator manually: import your estimator and run it in the basic vignettes above.\n",
    "6. to test your estimator automatically: call `sktime.tests.test_all_estimators.check_estimator` on your estimator. You can call this on a class or object instance. Ensure you have specified test parameters in the `get_test_params` method, according to the extension template.\n",
    "\n",
    "In case of direct contribution to `sktime` or one of its affiliated packages, additionally:\n",
    "* add yourself as an author to the code, and to the `CODEOWNERS` for the new estimator file(s).\n",
    "* create a pull request that contains only the new estimators (and their inheritance tree, if it's not just one class), as well as the automated tests as described above.\n",
    "* in the pull request, describe the estimator and optimally provide a publication or other technical reference for the strategy it implements.\n",
    "* before making the pull request, ensure that you have all necessary permissions to contribute the code to a permissive license (BSD-3) open source project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Credits: notebook 2 - time series panel tasks - classification, regression, clustering\n",
    "\n",
    "notebook creation: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sktime-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
