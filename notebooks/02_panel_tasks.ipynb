{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of this notebook\n",
    "\n",
    "This notebook:\n",
    "\n",
    "* introduction to time series classification, regression, clustering\n",
    "* `sktime` data format fo \"time series panels\" = collections of time series\n",
    "* basic vignettes for TSC, TSR, TScl\n",
    "* advanced vignettes - pipelines, ensembles, tuning\n",
    "* appendix: data loading\n",
    "* appendix: implementing third party estimators for TSC, TSR, TScl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Learning tasks - Classification, Regression, Clustering & more\n",
    "\n",
    "#### What are Panel tasks?\n",
    "\n",
    "Panel tasks refers to a type of learning problem where a Panel of data is employed, simply refered to as Panel Data.\n",
    "\n",
    "Panel Data comprises of multiple time series entities/instances, where a single time series component looks like:\n",
    "\n",
    "<INSERT TIME-SERIES, Image-1>\n",
    "\n",
    "Hence, Panel Data can be visualized as follows:\n",
    "\n",
    "<INSERT PANEL-DATA, Image-2>\n",
    "\n",
    "As per the kind of response variable and goal of the task, we can define different tasks - all of them are synonymous to time-independent (often called as Cross-sectional) data:\n",
    "1. _Classification_: The response variable is a label (Good / bad, ratings between 0 and 5 - 0, 1, 2, 3, 4, 5)\n",
    "    <INSERT CLASSIFICATION-BOXES, Image-3>\n",
    "2. _Regression_: The response variable is continuous (floating point, integers)\n",
    "    <INSERT REGRESSION-PLOT FROM `utils.load_experiments(variables=\"pressure\"), Image-4`>\n",
    "3. _Clustering_: There are no response variables here, the goal of this task is to group entities that are \"similar\" to each other.\n",
    "    <INSERT CLUSTERING-PLOT, Image-5>\n",
    "4. _Forecasting_: Given historical data, predict the (near future) values by capturing temporal dependencies and patterns within each panel.\n",
    "    <TODO - Think of what image to add here, Image-6>\n",
    "5. _TODO: Add more obscure tasks (causal inference, survival analysis) or something more relevant to the talk - distances and kernel based_\n",
    "    <TODO - Think of what image to add here, Image-7>\n",
    "\n",
    "NOTE - same formats used for forecasting, transformers, etc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Panel data - `sktime` data formats\n",
    "\n",
    "Preferred format 1: `pd.DataFrame` with 2-level `MultiIndex`, (instance, time), cols= variables\n",
    "\n",
    "Preferred format 2: 3D `np.ndarray` with index (instance, variable, time)\n",
    "\n",
    "* `sktime` supports and recognizes multiple data formats for convenience and internal use, e.g., `dask`, `xarray`\n",
    "* abstract data type = \"scitype\"; in-memory specification = \"mtype\"\n",
    "* More information in tutorial on [in-memory data representations and data loading](https://www.sktime.net/en/latest/examples/AA_datatypes_and_datasets.html#In-memory-data-representations-and-data-loading)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 preferred format 1 - `pd-multiindex` specification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd-multiindex` = `pd.DataFrame` with 2-level `MultiIndex`, (instance, time), cols= variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_osuleaf\n",
    "\n",
    "# load an example time series panel in pd-multiindex mtype\n",
    "X, _ = load_osuleaf(return_type=\"pd-multiindex\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The osuleaf dataset has:\n",
    "\n",
    "* 412 individual time series instances\n",
    "* one single variable per time series instances, `dim_0`\n",
    "* individual time series are observed at 100 time points (the same number for all instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_basic_motions\n",
    "\n",
    "# load an example time series panel in pd-multiindex mtype\n",
    "X, _ = load_basic_motions(return_type=\"pd-multiindex\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic motions dataset has:\n",
    "\n",
    "* 6 individual time series instances\n",
    "* six variables per time series instance, `dim_0` to `dim_5`\n",
    "* individual time series are observed at 100 time points (the same number for all instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 preferred format 2 - `numpy3D` specification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numpy3D` = 3D `np.ndarray` with index (instance, variable, time)\n",
    "\n",
    "instance/time index is interpreted as integer\n",
    "\n",
    "IMPORTANT: unlike `pd-multiindex`, this assumes:\n",
    "\n",
    "* all individual series have the same length\n",
    "* all individual series have the same index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_osuleaf\n",
    "\n",
    "# load an example time series panel in numpy mtype\n",
    "X, _ = load_osuleaf(return_type=\"numpy3D\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The osuleaf dataset has:\n",
    "\n",
    "* 412 individual time series instances\n",
    "* one single variable per time series instances\n",
    "* individual time series are observed at 100 time points (the same number for all instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_basic_motions\n",
    "\n",
    "# load an example time series panel in numpy mtype\n",
    "X, _ = load_basic_motions(return_type=\"numpy3D\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic motions dataset has:\n",
    "\n",
    "* 6 individual time series instances\n",
    "* six variables per time series instance\n",
    "* individual time series are observed at 100 time points (the same number for all instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 loading and validity checking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for custom data sets:\n",
    "\n",
    "1. use `pandas` `read_csv` or similar utilities to obtain a `pd.DataFrame` or `np.ndarray`\n",
    "2. try to bring the result in one of the preferred specifications\n",
    "3. use the `check_is_mtype` utility to check compliance - inspect informative error messages\n",
    "4. repeate 2-3 until the data format check passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's pretend we just loaded this from csv\n",
    "from sktime.datasets import load_osuleaf\n",
    "\n",
    "X_pd, _ = load_osuleaf(return_type=\"pd-multiindex\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's now check whether it complies with the `pd-multiindex` specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datatypes import check_is_mtype\n",
    "\n",
    "valid, error_msg, metadata = check_is_mtype(X_pd, \"pd-multiindex\", return_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is it valid?\n",
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpful metadata, check if this is as per expectations\n",
    "metadata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's see what happens if it is not in the expected format.\n",
    "\n",
    "We have a `pd.DataFrame`, so if we check against `numpy3D`, it should complain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid, error_msg, metadata = check_is_mtype(X_pd, \"numpy3D\", return_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_msg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that we should first convert into `np.ndarray` as expected."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further details on data formats, see the tutorial on [in-memory data representations and data loading](https://www.sktime.net/en/latest/examples/AA_datatypes_and_datasets.html#In-memory-data-representations-and-data-loading).\n",
    "\n",
    "The \"datatypes\" tutorial also contains:\n",
    "\n",
    "* full formal specifications of the mtypes (= machine representations)\n",
    "* common examples for loading from csv and formatting\n",
    "* utilities for loading data for commonly used benchmark problems\n",
    "\n",
    "All supported in-memory representations are python inspectable in `sktime.datatypes.MTYPE_REGISTER`\n",
    "\n",
    "Note that this includes \"exotic\", rarely used ones and representations of objects that aren't time series.\n",
    "Formats for time series panels are indicated by the `Panel` mtype.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Time Series Classification, Regression, Clustering - Basic Vignettes\n",
    "\n",
    "Above tasks are very similar to \"tabular\" classification, regression, clustering, as in `sklearn`\n",
    "\n",
    "Main distinction:\n",
    "* in \"tabular\" classification etc, one (feature) instance row vector of features\n",
    "* in TSC, one (feature) instance is a full time series, possibly unequal length, distinct index set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: INSERT HELPFUL PICTURE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "More formally:\n",
    "\n",
    "* \"tabular\" classification: training pairs $(x_1, y_1), \\dots, (x_n, y_n)$, where $x_i$ are rows of a `pd.DataFrame` (same col types), and $y_i \\in \\mathcal{C}$ for a finite set $y_i \\in \\mathcal{C}$. We use these to train a classifier that predicts $y_* \\in \\mathcal{C}$ for a `pd.DataFrame` row $x_*$\n",
    "* time series classification: training pairs $(x_1, y_1), \\dots, (x_n, y_n)$, where $x_i$ are time series from a certain domain, and $y_i \\in \\mathcal{C}$ for a finite set $y_i \\in \\mathcal{C}$. We use these to train a classifier that predicts $y_* \\in \\mathcal{C}$ for time series $x_*$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "very similar for time series regression, clustering - exercise left to reader :-)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sktime` design implications:\n",
    "\n",
    "* need representation of collections of time series (panels), see Section 2.1\n",
    "    * same as in \"adjacent\" learning tasks, e.g., panel forecasting\n",
    "    * same as for transformation estimators\n",
    "* algorithms that use sequentiality, can deal with unequal length etc\n",
    "* algorithms usually based on distances or kernels between time series - need to cover that in framework\n",
    "* but we can use familiar `fit` / `predict` and `scikit-learn` / `scikit-base` interface!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Time Series Classification - deployment vignette"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic deployment vignette for TSC:\n",
    "\n",
    "1. load/setup training data, `X` in a `Panel` format, `y` as 1D `np.ndarray`\n",
    "2. load/setup new data for prediction (can be done after 2 too)\n",
    "3. specify the classifier using `sklearn`-like syntax\n",
    "4. fit classifier to training data, `fit(X, y)`\n",
    "5. predict labels on new data, `predict(X_new)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps 1, 2 - prepare osuleaf dataset (train and new)\n",
    "from sktime.datasets import load_osuleaf\n",
    "\n",
    "X_train, y_train = load_osuleaf(split=\"train\", return_type=\"numpy3D\")\n",
    "X_new, _ = load_osuleaf(split=\"test\", return_type=\"numpy3D\")\n",
    "X_new = X_new[:2]  # smaller dataset for faster notebook runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is in numpy3D format, but could also be pd-multiindex or other\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 - specify the classifier\n",
    "\n",
    "# example 1 - 3-NN with simple dynamic time warping distance (requires numba)\n",
    "clf = KNeighborsTimeSeriesClassifier(n_neighbors=3)\n",
    "\n",
    "# example 2:\n",
    "# 3-nearest neighbour classifier with mean (over time points) pairwise Euclidean distance\n",
    "# (requires scipy)\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.dists_kernels.compose_tab_to_panel import AggrDist\n",
    "from sktime.dists_kernels import ScipyDist\n",
    "\n",
    "mean_eucl_dist = AggrDist(ScipyDist())\n",
    "clf = KNeighborsTimeSeriesClassifier(n_neighbors=3, distance=mean_eucl_dist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we could specify any `sktime` classifier here - the rest remains the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all classifiers is scikit-learn / scikit-base compatible!\n",
    "# nested parameter interface via get_params, set_params\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4 - fit/train the classifier\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the classifier is now fitted\n",
    "clf.is_fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and we can inspect fitted parameters if we like\n",
    "clf.get_fitted_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5 - predict labels on new data\n",
    "y_pred = clf.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred is an 1D np.ndarray, similar to sklearn classification output\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all together in one cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps 1, 2 - prepare osuleaf dataset (train and new)\n",
    "from sktime.datasets import load_osuleaf\n",
    "\n",
    "X_train, y_train = load_osuleaf(split=\"train\", return_type=\"pd-multiindex\")\n",
    "X_new, _ = load_osuleaf(split=\"test\", return_type=\"pd-multiindex\")\n",
    "X_new = X_new.loc[:2]  # smaller dataset for faster notebook runtime\n",
    "\n",
    "# step 3 - specify the classifier\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "\n",
    "clf = KNeighborsTimeSeriesClassifier(n_neighbors=3)\n",
    "\n",
    "# step 4 - fit/train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# step 5 - predict labels on new data\n",
    "y_pred = clf.predict(X_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 Time Series Classification - simple evaluation vignette"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation is simila to `sklearn` classifiers - we split a dataset and evaluate performance on the test set.\n",
    "\n",
    "This includes as additional steps:\n",
    "\n",
    "* splitting the initial, historical data, e.g., using `train_test_split`\n",
    "* comparing predictions with a held out data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.datasets import load_osuleaf\n",
    "\n",
    "# data should be split inti train/test\n",
    "X_train, y_train = load_osuleaf(split=\"train\", return_type=\"pd-multiindex\")\n",
    "X_test, y_test = load_osuleaf(split=\"test\", return_type=\"pd-multiindex\")\n",
    "\n",
    "# step 3-5 are the same\n",
    "clf = KNeighborsTimeSeriesClassifier(n_neighbors=3)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# for simplest evaluation, compare ground truth to predictions\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 Time Series Regression - basic vignettes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 --TODO: Decide Topic Name--: A small list of famous & simple estimators to 'solve' this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO-1: Estimator-1\n",
    "# TODO-2: Estimator-2\n",
    "# TODO-3: Estimator-3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Evaluation Metrics for Time Series Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: `scikit-learn` compatibility showcase for evaluation, provide in-house evaluation functions too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: `scikit-learn` compatibility showcase for evaluation, provide in-house evaluation functions too"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Introduction to Pipelines in `sktime`\n",
    "    -- TODO: Decide subtopic distribution --"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Advanced Topics\n",
    "    -- TODO : Choose 2 or 3 of the following\n",
    "        - DL estimators\n",
    "        - Extending both classical and DL estimators for different tasks\n",
    "        - Combining pipelines with DL estimators\n",
    "        - GridSearch Pipelines\n",
    "        - Reduction Pipelines-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sktime-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
